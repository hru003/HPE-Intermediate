{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af1d8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark  \n",
    "findspark.init()  \n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "407441b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create new sparkSession\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"IndexToStringExample and ngrams\")\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ea0b89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed string column 'category' to indexed column 'categoryIndex'\n",
      "+---+--------+-------------+\n",
      "| id|category|categoryIndex|\n",
      "+---+--------+-------------+\n",
      "|  0|       a|          0.0|\n",
      "|  1|       b|          1.0|\n",
      "|  2|       c|          2.0|\n",
      "|  3|       d|          3.0|\n",
      "|  4|       e|          4.0|\n",
      "|  5|       a|          0.0|\n",
      "+---+--------+-------------+\n",
      "\n",
      "Labels of StringIndexer are stored in output column metadata\n",
      "\n",
      "Output indexed column 'categoryIndex' back to original string column 'originalCategory' using labels in metadata\n",
      "+---+-------------+----------------+\n",
      "| id|categoryIndex|originalCategory|\n",
      "+---+-------------+----------------+\n",
      "|  0|          0.0|               a|\n",
      "|  1|          1.0|               b|\n",
      "|  2|          2.0|               c|\n",
      "|  3|          3.0|               d|\n",
      "|  4|          4.0|               e|\n",
      "|  5|          0.0|               a|\n",
      "+---+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import from pyspark from ml \n",
    "from pyspark.ml.feature import IndexToString, StringIndexer\n",
    "\n",
    "# Create the dataframe for string \n",
    "df = spark.createDataFrame(\n",
    "     [(0, \"a\"), (1, \"b\"), (2, \"c\"), (3, \"d\"), (4, \"e\"), (5, \"a\")],\n",
    "     [\"id\", \"category\"])\n",
    "\n",
    "#Conversion of string to index \n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\")\n",
    "model = indexer.fit(df)\n",
    "indexed_output = model.transform(df)\n",
    "\n",
    "print(\"Transformed string column '%s' to indexed column '%s'\"\n",
    "      % (indexer.getInputCol(), indexer.getOutputCol()))\n",
    "indexed_output.show()\n",
    "\n",
    "print(\"Labels of StringIndexer are stored in output column metadata\\n\")\n",
    "\n",
    "#Conversion of index to string\n",
    "converter = IndexToString(inputCol=\"categoryIndex\", outputCol=\"originalCategory\")\n",
    "converted = converter.transform(indexed)\n",
    "\n",
    "print(\"Output indexed column '%s' back to original string column '%s' using \"\n",
    "      \"labels in metadata\" % (converter.getInputCol(), converter.getOutputCol()))\n",
    "converted.select(\"id\", \"categoryIndex\", \"originalCategory\").show()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b931cf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------+\n",
      "|ngrams                                                                                 |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "|[Hi I heard, I heard about, heard about learn, about learn Python]                     |\n",
      "|[I desire Spark, desire Spark could, Spark could use, could use case, use case classes]|\n",
      "|[Linear regression models, regression models are, models are fast]                     |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "# Example on n gram for words\n",
    "wordDataFrame = spark.createDataFrame([\n",
    "            (0, [\"Hi\", \"I\", \"heard\", \"about\", \"learn\", \"Python\"]),\n",
    "            (1, [\"I\", \"desire\", \"Spark\", \"could\", \"use\", \"case\", \"classes\"]),\n",
    "            (2, [\"Linear\", \"regression\", \"models\", \"are\", \"fast\"])\n",
    "            ], [\"id\", \"words\"])\n",
    "\n",
    "ngram = NGram(n=3, inputCol=\"words\", outputCol=\"ngrams\")\n",
    "\n",
    "ngramDataFrame = ngram.transform(wordDataFrame)\n",
    "ngramDataFrame.select(\"ngrams\").show(truncate=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7d0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
